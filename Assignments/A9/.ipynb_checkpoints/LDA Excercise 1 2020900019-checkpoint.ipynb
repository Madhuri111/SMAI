{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 1\n",
    "\n",
    "In the tutorial you saw how to compute LDA for a two class problem. In this excercise we will work on a multi-class problem. We will be working with the famous Iris dataset that has been deposited on the UCI machine learning repository\n",
    "(https://archive.ics.uci.edu/ml/datasets/Iris).\n",
    "\n",
    "The iris dataset contains measurements for 150 iris flowers from three different species.\n",
    "\n",
    "The three classes in the Iris dataset:\n",
    "1. Iris-setosa (n=50)\n",
    "2. Iris-versicolor (n=50)\n",
    "3. Iris-virginica (n=50)\n",
    "\n",
    "The four features of the Iris dataset:\n",
    "1. sepal length in cm\n",
    "2. sepal width in cm\n",
    "3. petal length in cm\n",
    "4. petal width in cm\n",
    "\n",
    "<img src=\"iris_petal_sepal.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import mode\n",
    "from collections import Counter \n",
    "import numpy as np\n",
    "import seaborn as sns; sns.set();\n",
    "import pandas as pd\n",
    "from itertools import combinations \n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal-length</th>\n",
       "      <th>sepal-width</th>\n",
       "      <th>petal-length</th>\n",
       "      <th>petal-width</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal-length  sepal-width  petal-length  petal-width           Class\n",
       "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
       "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
       "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
       "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
       "149           5.9          3.0           5.1          1.8  Iris-virginica"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'Class']\n",
    "dataset = pd.read_csv(url, names=names)\n",
    "\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal-length</th>\n",
       "      <th>sepal-width</th>\n",
       "      <th>petal-length</th>\n",
       "      <th>petal-width</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal-length  sepal-width  petal-length  petal-width           Class\n",
       "0             5.1          3.5           1.4          0.2     Iris-setosa\n",
       "1             4.9          3.0           1.4          0.2     Iris-setosa\n",
       "2             4.7          3.2           1.3          0.2     Iris-setosa\n",
       "3             4.6          3.1           1.5          0.2     Iris-setosa\n",
       "4             5.0          3.6           1.4          0.2     Iris-setosa\n",
       "..            ...          ...           ...          ...             ...\n",
       "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
       "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
       "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
       "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
       "149           5.9          3.0           5.1          1.8  Iris-virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "\n",
    "Once dataset is loaded into a pandas data frame object, the first step is to divide dataset into features and corresponding labels and then divide the resultant dataset into training and test sets. The following code divides data into labels and feature set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 0:4].values\n",
    "y = dataset.iloc[:, 4].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above script assigns the first four columns of the dataset i.e. the feature set to X variable while the values in the fifth column (labels) are assigned to the y variable.\n",
    "\n",
    "The following code divides data into training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "y_train = np.reshape(y_train, ((-1, 1)))\n",
    "y_test = np.reshape(y_test, ((-1, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Scaling\n",
    "\n",
    "We will now perform feature scaling as part of data preprocessing too. For this task, we will be using scikit learn `StandardScalar`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write your code below\n",
    "\n",
    "Write you code below to LDA on the IRIS dataset and compute the overall accuracy of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### WRITE YOUR CODE HERE ####\n",
    "\n",
    "# Calculating covariance of an input matrix\n",
    "def calc_cov_matrix(X_input):\n",
    "    n_samples = np.shape(X_input)[0]\n",
    "    cov_matrix = np.array((1 / (n_samples-1)) * (X_input - X_input.mean(axis=0)).T.dot(X_input - X_input.mean(axis=0)))\n",
    "    return cov_matrix\n",
    "\n",
    "def train(X_train, y_train):\n",
    "\n",
    "    \"\"\"Train method for LDA.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    X_train: ndarray (num_examples(rows) vs num_features(columns))\n",
    "    Input dataset which LDA will use to obtain optimal weights during training\n",
    "\n",
    "    y_train: ndarray (num_examples(rows) vs class_labels(columns))\n",
    "    \"\"\"\n",
    "\n",
    "    # Collecting all class 0 and class 1 into separate variables\n",
    "    class_X0 = X_train[np.argwhere(y_train == 0)[:, 0]]\n",
    "    class_X1 = X_train[np.argwhere(y_train == 1)[:, 0]]\n",
    "\n",
    "    # Getting number of examples in each class\n",
    "    num_class_X0_samples = np.shape(class_X0)[0]\n",
    "    num_class_X1_samples = np.shape(class_X1)[0]\n",
    "\n",
    "    # Computing class mean for each label and calculating the difference between them.\n",
    "    class_X0_mean = class_X0.mean(0)\n",
    "    class_X1_mean = class_X1.mean(0)\n",
    "    class_mean_diff = class_X1_mean - class_X0_mean\n",
    "    class_mean_diff = class_mean_diff.reshape((-1, 1))\n",
    "    SB = np.dot(class_mean_diff, class_mean_diff.T)\n",
    "\n",
    "    # Calculating covariance matrix\n",
    "    cov_mat_class_X0 = calc_cov_matrix(class_X0)\n",
    "    cov_mat_class_X1 = calc_cov_matrix(class_X1)\n",
    "    #SW = num_class_X0_samples * cov_mat_class_X0 + num_class_X0_samples * cov_mat_class_X1\n",
    "    SW = cov_mat_class_X0 + cov_mat_class_X1\n",
    "\n",
    "    eigvals, eigvecs = np.linalg.eig(np.linalg.pinv(SW).dot(SB))\n",
    "\n",
    "    # Getting the eigenvectors with the maximum eigenvalue.\n",
    "    idx = eigvals.argsort()[::-1]\n",
    "    eigvals = eigvals[idx][:1]\n",
    "    weights = np.atleast_1d(eigvecs[:, idx])[:, :1]\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_vs_all(X_train, Y_train, base_weights, num_epochs=1000, learning_rate=0.1):\n",
    "    n_samples, n_features = np.shape(X_train)\n",
    "    history_weights = []\n",
    "    epoch = 1\n",
    "    classes = np.unique(Y_train)\n",
    "    print(\"-------------\")\n",
    "    print(\"Creating One vs Rest Classifier....\")\n",
    "    print(\"Number of Classifiers needed: (N) =\", len(classes))\n",
    "    print(\"-------------\")\n",
    "    # Training using Batch GD\n",
    "    for k in classes:\n",
    "        # one-vs-all binary classifier\n",
    "        binary_y_train = np.where(Y_train == k, 1, 0)\n",
    "        trained = train(data_x, binary_y_train)\n",
    "        history_weights.append(trained)\n",
    "    print()\n",
    "    print(\"Training Complete!\")\n",
    "    print()\n",
    "    return history_weights   \n",
    "\n",
    "def getPredictionOvA(X_test, Y_test, trained_weights):\n",
    "    \n",
    "    num_test_samples = np.shape(Y_test)[0]\n",
    "    y_test_predicted = np.dot(X_test, trained_weights)\n",
    "    y_test_predicted = y_test_predicted.reshape((-1, 1))\n",
    "    return y_test_predicted.astype(np.uint8)\n",
    "\n",
    "# Compute the accuracy of training data and validation data\n",
    "def predict_one_vs_all(X_input, Y_input, trained_weights):\n",
    "    num_classes = np.unique(Y_input)\n",
    "    scores = np.zeros((len(num_classes), (X_input.shape)[0]))\n",
    "    for k in range(len(num_classes)):\n",
    "        binary_y_input = np.where(Y_input == num_classes[k], 1, 0)\n",
    "        individual_scores = getPredictionOvA(X_input, Y_input, trained_weights[k])\n",
    "        individual_scores = individual_scores.reshape((-1,))\n",
    "        \n",
    "        scores[k, :] = individual_scores\n",
    "    print(scores)  \n",
    "    pred_X = np.argmax(scores, axis=0)\n",
    "    predictions = pred_X.reshape((-1, 1))\n",
    "    Y = np.zeros(Y_input.shape)\n",
    "    for k in range(len(num_classes)):\n",
    "        Y[np.where(Y_input==num_classes[k])] = k\n",
    "    print(\"Y:\", Y)\n",
    "    print()\n",
    "    print(\"predictions:\", predictions)\n",
    "    acc = getAccuracy(predictions, Y)\n",
    "    return pred_X, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "Creating One vs One Classifier....\n",
      "Number of Classifiers needed: (N * (N-1)/2) = 3\n",
      "-------------\n",
      "Classifier Number:  1\n",
      "Training Classifier to Classify:  ('Iris-setosa', 'Iris-versicolor')\n",
      "Classifier Number:  2\n",
      "Training Classifier to Classify:  ('Iris-setosa', 'Iris-virginica')\n",
      "Classifier Number:  3\n",
      "Training Classifier to Classify:  ('Iris-versicolor', 'Iris-virginica')\n",
      "\n",
      "Training Complete!\n",
      "\n",
      "[[  1.   0. 254.   1. 255.   1. 255.   0.   0.   0.   1.   0.   0.   0.\n",
      "    0. 255.   0.   0. 255. 255.   1.   0. 255. 255.   0. 254. 255.   0.\n",
      "    0. 255.]\n",
      " [  1.   0. 255.   1. 255.   1. 255.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0. 255.   0.   0. 255. 255.   1.   0. 255. 255.   0. 255. 255.   0.\n",
      "    0. 255.]\n",
      " [255.   0.   2. 255.   1. 255.   1.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   1.   0.   0.   1.   1. 255.   0.   1.   1.   0.   1.   1.   0.\n",
      "    0.   1.]]\n",
      "Y: [[2.]\n",
      " [1.]\n",
      " [0.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [2.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [2.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "\n",
      "predictions: [[2]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "trained_weights_ova = train_OvO(X_train, y_train)\n",
    "\n",
    "res, acc= predict_one_vs_all(X_test, y_test, trained_weights_ova)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43333333333333335"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that splits the dataset into subsets and returns K(K-1)/2 classifier weights\n",
    "def train_OvO(X_train, Y_train):\n",
    "    a = np.hstack((X_train, Y_train))\n",
    "    x = list(combinations(np.unique(Y_train), 2))\n",
    "    N = len(np.unique(Y_train))\n",
    "    comb = 0\n",
    "    print(\"-------------\")\n",
    "    print(\"Creating One vs One Classifier....\")\n",
    "    print(\"Number of Classifiers needed: (N * (N-1)/2) =\", int((N * (N-1)/2)))\n",
    "    print(\"-------------\")\n",
    "    trained_weights = []\n",
    "    for c in x:\n",
    "        print(\"Classifier Number: \", comb + 1)\n",
    "        print(\"Training Classifier to Classify: \", c)\n",
    "        # Generating Subsets of Data by choosing combinations of two Classes\n",
    "        p_x = X_train[np.where(a[:,-1] == c[0])]\n",
    "        q_x = X_train[np.where(a[:,-1] == c[1])]\n",
    "        p_y = Y_train[np.where(a[:,-1] == c[0])]\n",
    "        q_y = Y_train[np.where(a[:,-1] == c[1])]\n",
    "        data_x = np.concatenate((p_x, q_x))\n",
    "        data_y = np.concatenate((p_y, q_y))\n",
    "        # Obtain the binary representation of the classes\n",
    "        binary_y_train = np.where(data_y == c[1], 1, 0)\n",
    "        # Train the binary classifier\n",
    "        trained = train(data_x, binary_y_train)\n",
    "        # Store the classifier's weights in a list\n",
    "        trained_weights.append(trained)\n",
    "        comb += 1\n",
    "    print()\n",
    "    print(\"Training Complete!\")\n",
    "    print()\n",
    "    return(trained_weights)\n",
    "\n",
    "def getPrediction(X_test, Y_test, trained_weights):\n",
    "    \n",
    "    num_test_samples = np.shape(Y_test)[0]\n",
    "    y_test_predicted = np.dot(X_test, trained_weights)\n",
    "    y_test_predicted[y_test_predicted >= 0] = 1\n",
    "    y_test_predicted[y_test_predicted < 0] = 0\n",
    "\n",
    "    y_test_predicted = y_test_predicted.reshape((-1, 1))\n",
    "    return y_test_predicted.astype(np.uint8)\n",
    "\n",
    "def getAccuracy(y_test_predicted, Y_test):\n",
    "    num_test_samples = np.shape(Y_test)[0]\n",
    "    miscls_test_points = np.unique(np.argwhere(y_test_predicted != Y_test)[:, 0])\n",
    "    accuracy = 1-(len(miscls_test_points)/num_test_samples)\n",
    "    return accuracy\n",
    "\n",
    "def most_frequent(lab): \n",
    "    lab = list(lab)\n",
    "    occurence_count = Counter(lab) \n",
    "    return occurence_count.most_common(1)[0][0] \n",
    "\n",
    "def OvO_Pred(X, Y, weights):\n",
    "    # Generate Combinations\n",
    "    c = list(combinations(np.unique(Y), 2))\n",
    "    # Create an array to store the predicted values\n",
    "    pred_array = []\n",
    "    for i in range(np.array(weights).shape[0]):\n",
    "        # Predict values based on individual classifier\n",
    "        pred = getPrediction(X, Y, weights[i])\n",
    "        # Obtain labels of the classified result\n",
    "        labels = np.where(pred == 1, c[i][1], c[i][0])\n",
    "        # Place the result in the result array\n",
    "        pred_array.append(labels)\n",
    "\n",
    "    pred_array = np.array(pred_array)\n",
    "    pred_array = np.hstack(pred_array)\n",
    "    res = [0]*Y.shape[0]\n",
    "    # Vote to get the maximum occuring label\n",
    "    for i in range(pred_array.shape[0]):\n",
    "        res[i] = most_frequent(pred_array[i])\n",
    "    res = np.reshape(np.array(res), (Y.shape))\n",
    "    # Obtain accuracy of the model\n",
    "    acc = getAccuracy(res, Y)\n",
    "    return np.array(pred_array), acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "Creating One vs One Classifier....\n",
      "Number of Classifiers needed: (N * (N-1)/2) = 3\n",
      "-------------\n",
      "Classifier Number:  1\n",
      "Training Classifier to Classify:  ('Iris-setosa', 'Iris-versicolor')\n",
      "Classifier Number:  2\n",
      "Training Classifier to Classify:  ('Iris-setosa', 'Iris-virginica')\n",
      "Classifier Number:  3\n",
      "Training Classifier to Classify:  ('Iris-versicolor', 'Iris-virginica')\n",
      "\n",
      "Training Complete!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trained_weights = train_OvO(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "res, acc= OvO_Pred(X_test, y_test, trained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7666666666666666"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Iris-setosa'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.unique(y_train)\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
