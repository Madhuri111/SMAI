{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fwxWcO7fqb-L"
   },
   "source": [
    "# Excercise - Multi-class classification of MNIST using Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vcygblmOmQDZ"
   },
   "source": [
    "In binary perceptron, where $\\mathbf{y} \\in \\{-1, +1\\}$, we used to update our weights only for wrongly classified examples.\n",
    "\n",
    "The multi-class perceptron is regarded as a generalization of binary perceptron. Learning through iteration is the same as the perceptron. Weighted inputs are passed through a multiclass signum activation function. If the predicted output label is the same as true label then weights are not updated. However, when predicted output label $\\neq$ true label, then the wrongly classified input example is added to the weights of the correct label and subtracted from the weights of the incorrect label. Effectively, this amounts to ’rewarding’ the correct weight vector, ’punishing’ the misleading, incorrect weight\n",
    "vector, and leaving alone an other weight vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "NBSGUCALSkXl"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Error importing SciPy: you cannot import SciPy while\n        being in scipy source directory; please exit the SciPy source\n        tree first and relaunch your Python interpreter.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/scipy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__config__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mshow_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scipy.__config__'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-946b8924f278>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_classification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_distributor_init\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__check_build\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_show_versions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_IS_32BIT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmurmurhash\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmurmurhash3_32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/scipy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mbeing\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0msource\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mplease\u001b[0m \u001b[0mexit\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mSciPy\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         tree first and relaunch your Python interpreter.\"\"\"\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Error importing SciPy: you cannot import SciPy while\n        being in scipy source directory; please exit the SciPy source\n        tree first and relaunch your Python interpreter."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import seaborn as sns; sns.set();\n",
    "import pandas as pd\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "gNkGLnbjTY-s"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datasets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7374d13727fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Loading digits datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdigits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_digits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# One-hot encoding of target label, Y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'datasets' is not defined"
     ]
    }
   ],
   "source": [
    "# Setting the seed to ensure reproducibility of experiments\n",
    "np.random.seed(11)\n",
    "\n",
    "# One-hot encoding of target label, Y\n",
    "def one_hot(a):\n",
    "    b = -1 * np.ones((a.size, a.max()+1))\n",
    "    b[np.arange(a.size), a] = 1\n",
    "    return b\n",
    "\n",
    "# Loading digits datasets\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# One-hot encoding of target label, Y\n",
    "Y = digits.target\n",
    "Y = one_hot(Y)\n",
    "\n",
    "# Adding column of ones to absorb bias b of the hyperplane into X\n",
    "X = digits.data\n",
    "bias_ones = np.ones((len(X), 1))\n",
    "X = np.hstack((X, bias_ones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "0BPvc5P8KvrM",
    "outputId": "ce4549e0-06c8-4c73-86a6-d6d7cc643910"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset:  (1257, 65)\n",
      "Validation dataset:  (180, 65)\n",
      "Test dataset:  (360, 65)\n"
     ]
    }
   ],
   "source": [
    "# Train-val-test data\n",
    "X_train_val, X_test, Y_train_val, Y_test = train_test_split(X, Y, shuffle=True, test_size = 0.2)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train_val, Y_train_val, test_size = 0.12517)\n",
    "\n",
    "print(\"Training dataset: \", X_train.shape)\n",
    "print(\"Validation dataset: \", X_val.shape)\n",
    "print(\"Test dataset: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "QPJZdeDtUfoy",
    "outputId": "5e7309c4-ec79-46fe-8dda-d0d7a38de075"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.reset_orig();\n",
    "\n",
    "plt.gray()\n",
    "plt.matshow(digits.images[10])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g2KVp57S1Zah"
   },
   "source": [
    "#### Write your code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "wdguhdUYS68O"
   },
   "outputs": [],
   "source": [
    "#signum function\n",
    "def signum(vec_wx): \n",
    "   vec_wx[vec_wx>=0]=1\n",
    "   vec_wx[vec_wx<0]=-1\n",
    "   return vec_wx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "D_5wwbHuS6WU"
   },
   "outputs": [],
   "source": [
    "def training(x,y):\n",
    "  weights=np.zeros(d)\n",
    "  for k in range(epochs):\n",
    "    mispred=np.multiply(y,signum(x@weights))\n",
    "    mispred=np.argwhere(mispred <= 0)[:, 0]\n",
    "    if(len(mispred)==0):\n",
    "      return weights\n",
    "    else:\n",
    "      weights += (learning_rate/trainsamples) * (np.dot((x[mispred]).T, y[mispred]))\n",
    "  return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "a1OnYYfFTGXg"
   },
   "outputs": [],
   "source": [
    "def accuracy(x,  y):\n",
    "    mispred=np.argwhere(np.multiply(y,signum(np.dot(x,weights.T)))<= 0)[:, 0]\n",
    "    return (1 - len(mispred)/x.shape[0]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "R-SM4tWXTMRV",
    "outputId": "e9f00588-b0d9-4e22-c4b3-5fabbdedb0ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuarcy is  94.03341288782816\n",
      "Validation Accuracy is  93.0410577592206\n",
      "Test Accuarcy is  86.38888888888889\n"
     ]
    }
   ],
   "source": [
    "# Main function used for trainin model and printing accuaracy\n",
    "#variables setting\n",
    "learning_rate=0.99\n",
    "trainsamples, d=X_train.shape\n",
    "epochs=1300\n",
    "totaldigits=10 \n",
    "weights=np.zeros(shape=(totaldigits,d))\n",
    "for digit in range(totaldigits):\n",
    "  weights[digit]= training(X_train,Y_train[:,digit])\n",
    "  \n",
    "train_accuracy=accuracy(X_train,Y_train)\n",
    "val_accuracy=accuracy(X_train_val,Y_train_val)\n",
    "test_accuracy=accuracy(X_test,Y_test)\n",
    "print(\"Train Accuarcy is \",train_accuracy)\n",
    "print(\"Validation Accuracy is \",val_accuracy)\n",
    "print(\"Test Accuarcy is \",test_accuracy )\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ZQQfFFOrqST3"
   ],
   "name": "Linear Perceptron Excercise.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
